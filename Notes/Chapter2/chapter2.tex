\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}
\stepcounter{chapter}

\begin{document}




\chapter{Differential Forms}
\section{Notes}
\begin{itemize}
    \item \marginnote{4/18:}Office Hours on Wednesday, 4:00-5:00 PM.
    \item Plan:
    \begin{itemize}
        \item An impressionistic overview of what (differential) forms do/are.
        \item Tangent spaces.
        \item Vector fields/integral curves.
        \item 1-forms; a warm-up to $k$-forms.
    \end{itemize}
    \item Impressionistic overview of the rest of \textcite{bib:DifferentialForms}.
    \begin{itemize}
        \item An open subset $U\subset\R^n$; $n=2$ and $n=3$ are nice.
        \item Sometimes, we'll have some functions $F:U\to V$; this is where pullbacks come into play.
        \item At every point $p\in U$, we'll define a vector space (the tangent space $T_p\R^n$). Associated to that vector space you get our whole slew of associated spaces (the dual space $T_p^*\R^n$, and all of the higher exterior powers $\lam[k]{T_p^*\R^n}$).
        \item We let $\omega\in\ome[k]{U}$ be a $k$-form in the space of $k$-forms.
        \item $\omega$ assigns (smoothly) to every point $p\in U$ an element of $\lam[k]{T_p^*\R^n}$.
        \item Question: What really is a $k$-form?
        \begin{itemize}
            \item Answer: Something that can be integrated on $k$-dimensional subsets.
            \item If $k=1$, i.e., $\omega\in\ome[1]{U}$, then $U$ can be integrated over curves.
        \end{itemize}
        \item If we take $k=0$, then $\ome[0]{U}=C^\infty(U)$, i.e., the set of all smooth functions $f:U\to\R$.
        \begin{itemize}
            \item \textcite{bib:DifferentialForms} doesn't, but Klug will and we should distinguish between functions $F:U\to V$ and $f:U\to\R$.
        \end{itemize}
        \item We will soon construct a map $d:\ome[0]{U}\to\ome[1]{U}$ (the \textbf{exterior derivative}) that is rather like the gradient but not quite.
        \begin{itemize}
            \item $d$ is linear.
            \item Maps from vector spaces are heretofore assumed to be linear unless stated otherwise.
        \end{itemize}
        \item The 1-forms in $\im(d)$ are special: $\int_\gamma\dd{f}=f(\gamma(b))-f(\gamma(a))$ only depends on the endpoints of $\gamma:[a,b]\to U$! The integral is \emph{path-independent}.
        \item A generalization of this fact is that instead of integrating along the surface $M$, we can integrate along the boundary curve:
        \begin{equation*}
            \int_M\dd{\omega} = \int_{\partial M}\omega
        \end{equation*}
        This is \textbf{Stokes' theorem}.
        \begin{itemize}
            \item $M$ is a $k$-dimensional subset of $U\subset\R^n$.
        \end{itemize}
        \item Note that we have all manner of functions $d$ that we could differentiate between (because they are functions) but nobody does.
        \begin{equation*}
            0 \rightarrow \ome[0]{U}
            \xrightarrow{d} \ome[1]{U}
            \xrightarrow{d} \ome[2]{U}
            \xrightarrow{d} \cdots
            \xrightarrow{d} \ome[n]{U}
            \xrightarrow{d} 0
        \end{equation*}
        \item Theorem: $d^2=d\circ d=0$.
        \begin{itemize}
            \item Corollary: $\im(d^{n-1})\subset\ker(d^n)$.
        \end{itemize}
        \item We'll define $H^k_{dR}(U)=\ker(d)/\im(d)$.
        \begin{itemize}
            \item These will be finite dimensional, even though all the individual vector spaces will be infinite dimensional.
            \item These will tell us about the shape of $U$; basically, if all of these equal zero, $U$ is simply connected. If some are nonzero, $U$ has some holes.
        \end{itemize}
        \item For small values of $n$ and $k$, this $d$ will have some nice geometric interpretations (div, grad, curl, n'at).
        \item We'll have additional operations on forms such as the wedge product.
    \end{itemize}
    \item \textbf{Tangent space} (of $p$): The following set. \emph{Denoted by} $\bm{T_p\pmb{\R}^n}$. \emph{Given by}
    \begin{equation*}
        T_p\R^n = \{(p,v):v\in\R^n\}
    \end{equation*}
    \begin{itemize}
        \item This is naturally a vector space with addition and scalar multiplication defined as follows.
        \begin{align*}
            (p,v_1)+(p,v_2) &= (p,v_1+v_2)&
            \lambda(p,v) &= (p,\lambda v)
        \end{align*}
        \item The point is that
        \begin{equation*}
            T_p\R^n \neq T_q\R^n
        \end{equation*}
        for $p\neq q$ even though the spaces are isomorphic.
        \item Aside: $F:U\to V$ differentiable and $p\in U$ induce a map $\dd{F_p}:T_p\R^n\to T_{F(p)}\R^m$ called the "derivative at $p$."
        \begin{itemize}
            \item We will see that the matrix of this map is the Jacobian.
        \end{itemize}
        \item Chain rule: If $U\xrightarrow{F}V\xrightarrow{G}W$, then
        \begin{equation*}
            \dd{(G\circ F)_p} = \dd{G}_{F(p)}\circ\dd{F_p}
        \end{equation*}
    \end{itemize}
    \item This is round 1 of our discussion on tangent spaces.
    \item Round 2, later on, will be submanifolds such as $T_pM$: The tangent space to a point $p$ of a manifold $M$.
    \item \textbf{Vector field} (on $U$): A function that assigns to each $p\in U$ an element of $T_p\R^n$.
    \begin{itemize}
        \item A constant vector field would be $p\mapsto(p,v)$, visualized as a field of vectors at every $p$ all pointing the same direction. For example, we could take $v=(1,1)$.
        \emph{picture}
        \item Special case: $v=e_1,e_2,\dots,e_n$. Here we use the notation $e_i=\dv*{x_i}$.
        \item Example: $n=2$, $U=\R^2\setminus\{(0,0)\}$. We could take a vector field that spins us around in circles.
        \item Notice that for all $p$, $\dv*{x_1}|_p,\dots,\dv*{x_n}|_p\in T_p\R^n$ are a basis.
        \begin{itemize}
            \item Thus, any vector field $v$ on $U$ can be written uniquely as
            \begin{equation*}
                v = f_1\dv{x_1}+\cdots+f_n\dv{x_n}
            \end{equation*}
            where the $f_1,\dots,f_n$ are functions $f_i:U\to\R$.
        \end{itemize}
    \end{itemize}
    \item \marginnote{4/20:}Plan:
    \begin{itemize}
        \item Vector fields and their integral curves.
        \item Lie derivatives.
        \item 1-forms and $k$-forms.
        \item $\ome[0]{U}\xrightarrow{d}\ome[1]{U}$.
    \end{itemize}
    \item Notation.
    \begin{itemize}
        \item $U\subset\R^n$.
        \item $v$ denotes a vector field on $U$.
        \begin{itemize}
            \item Note that the set of all vector fields on $U$ constitute the vector space ??.
        \end{itemize}
        \item $v_p\in T_p\R^n$.
        \item $\omega_p\in\lam[k]{T_p^*\R^n}$.
        \item $\dv*{x_i}|_p=(p,e_i)\in T_p\R^n$.
    \end{itemize}
    \item Recall that any vector field $v$ on $U$ can be written uniquely as
    \begin{equation*}
        v = g_1\dv{x_1}+\cdots+g_n\dv{x_n}
    \end{equation*}
    where the $g_i:U\to\R$.
    \item \textbf{Smooth} (vector field): A vector field $v$ for which all $g_i$ are smooth.
    \item From now on, we assume unless stated otherwise that all vector fields are smooth.
    \item \textbf{Lie derivative} (of $f$ wrt. $v$): The function $L_vf:U\to\R$ defined by $p\mapsto D_{v_p}(f)(p)$, where $v$ is a vector field on $U$ and $f:U\to\R$ (always smooth).
    \begin{itemize}
        \item Recall that $D_{v_p}(f)(p)$ denotes the directional derivative of $f$ in the direction $v_p$ at $p$.
        \item As some examples, we have
        \begin{align*}
            L_{\dv*{x_i}}f &= \dv{f}{x_i}&
            L_{(g_1\dv{x_1}+\cdots+g_n\dv{x_n})}f &= g_1\dv{f}{x_1}+\cdots+g_n\dv{f}{x_n}
        \end{align*}
    \end{itemize}
    \item Property.
    \begin{enumerate}
        \item Product rule: $L_v(f_1f_2)=(L_vf_1)f_2+f_1(L_vf_2)$.
    \end{enumerate}
    \item Later: Geometric meaning to the expression $L_vf=0$.
    \begin{itemize}
        \item Satisfied iff $f$ is constant on the integral curves of $v$. As if $f$ "flows along" the vector field.
    \end{itemize}
    \item We define $T_p^*\R^n=(T_p\R^n)^*$.
    \item 1-forms:
    \begin{itemize}
        \item A (differential) 1-form on $U\subset\R^n$ is a function $\omega:p\mapsto\omega_p\in T_p^*\R^n$.
        \item A "co-vector field"
    \end{itemize}
    \item Notation: $\dd{x_i}$ is the 1-form that at $p$ is $(p,e_i^*)\in T_p^*\R^n$.
    \item For example, if $U=\R^2$ and $\omega=\dd{x_1}$, then we have the vector field of "unit vectors pointing to the right at each point."
    \item Note: Given any 1-form $\omega$ on $U$, we can write $\omega$ uniquely as
    \begin{equation*}
        \omega = g_1\dd{x_1}+\cdots+g_n\dd{x_n}
    \end{equation*}
    for some set of smooth $g_i:U\to\R$.
    \item Notation:
    \begin{itemize}
        \item $\ome[1]{U}$ is the set of all smooth 1-forms.
        \item Notice that $\ome[1]{U}$ is a vector space.
    \end{itemize}
    \item Given $\omega\in\ome[1]{U}$ and a vector field $v$ on $U$, we can define $\omega(v):U\to\R$ by $p\mapsto\omega_p(v_p)$.
    \item If $U=\R^2$, we have that
    \begin{align*}
        \dd{x}\left( \dv{x} \right) &= 1&
        \dd{x}\left( \dv{y} \right) &= 0
    \end{align*}
    \item Note that $\dd{x},\dd{y}$ are not a basis for $\ome[1]{U}$ since the latter is infinite dimensional.
    \item Exterior derivative for 0/1 forms.
    \begin{itemize}
        \item Let $d:\ome[0]{U}\to\ome[1]{U}$ take $f:U\to\R$ to $\pdv{f}{x_1}\dd{x_1}+\cdots+\pdv{f}{x_n}\dd{x_n}$.
        \item This represents the gradient as a 1-form.
    \end{itemize}
    \item Check:
    \begin{enumerate}
        \item Linear.
        \item $\dd{x_i}=\dd{(x_i)}$, where $x_i:\R^n\to\R$ is the $i^\text{th}$ coordinate function.
    \end{enumerate}
    \item \marginnote{4/22:}Plan:
    \begin{itemize}
        \item Clear up a bit of notational confusion.
        \item Discuss integral curves of vectors fields.
        \item $k$-forms.
        \item Exterior derivatives $d:\ome[k]{U}\to\ome[k+1]{U}$ (definition and properties).
    \end{itemize}
    \item Notation:
    \begin{itemize}
        \item $F:\R^n\to\R^m$ smooth.
        \item We are used to denoting derivatives by big $D$: $DF_p:T_p\R^n\to T_{f(p)}\R^m$ where bases of the two spaces are $e_1,\dots,e_n$ and $e_1,\dots,e_m$ has matrix equal to the Jacobian:
        \begin{equation*}
            [DF_p] =
            \begin{bmatrix}
                {\dv{F_i}{x_j}}(p)
            \end{bmatrix}
        \end{equation*}
        \item The book often uses small $d$: $f:U\to\R$ has $df_p:T_p\R^n\to T_{f(p)}\R$, where the latter set is isomorphic to $\R$.
        \item $df:p\to df_p\in T_p^*\R^n$.
        \item Klug said
        \begin{equation*}
            \dd{f} = \sum_{i=1}^n\pdv{f}{x_i}\dd{x_i}
        \end{equation*}
        \item Homework 1 defined $\dd{f}=df$?
        \item Sometimes three perspectives help you keep this all straight:
        \begin{enumerate}
            \item Abstract nonsense: The definition of the derivative.
            \item How do I compute it: Apply the formula.
            \item What is it: E.g., magnitude of the directional derivative in the direction of steepest ascent.
        \end{enumerate}
    \end{itemize}
    \item For the homework,
    \begin{itemize}
        \item Let $\omega$ be a 1-form in $\ome[1]{U}$.
        \item Let $\gamma:[a,b]\to U$ be a curve in $U$.
        \item Then $\dd{\gamma_p}=\gamma_p':T_p\R\to T_{\gamma(p)}\R^n$ is a function that takes in points of the curve and spits out tangent vectors.
        \item Integrating swallows 1-forms and spits out numbers.
        \begin{equation*}
            \int_\gamma\omega = \int_a^b\omega(\gamma'(t))\dd{t}
        \end{equation*}
        \item Problem: If $\omega=\dd{f}$, then
        \begin{equation*}
            \int_\gamma\omega = f(\gamma(b))-f(\gamma(a))
        \end{equation*}
        regardless of the path.
        \item Question: Given a 1-form $\omega$, is $\omega=\dd{f}$ for some $f$?
        \item Homework: Explicit $U$, $\omega$, closed $\gamma$ such that $\int_\gamma\omega\neq 0$ implies that $\omega\neq\dd{f}$. This motivates and leads into the de Rham cohomology.
    \end{itemize}
    \item Aside: It won't hurt (for now) to think of 1-forms as vector fields.
    \item Integral curves: Let $U\subset\R^n$, $v$ be a (smooth) vector field on $U$. A curve $\gamma:(a,b)\to U$ is an \textbf{integral curve} for $v$ if $\gamma'(t)=v_{\gamma(t)}$.
    \item Examples:
    \begin{itemize}
        \item If $U=\R^2$ and $\gamma=\dv*{x}$, then the integral curve is the line from left to right traveling at unit speed. The curve has to always have as it's tangent vector the unit vector pointing right (which is the vector at every point in the vector field).
        \item Vector fields flow everything around. An integral curve is the trajectory of a particle subjected to the vector field as a force field.
    \end{itemize}
    \item Main points:
    \begin{enumerate}
        \item These integral curves always exist (locally) and often exist globally (cases in which they do are called \textbf{complete vector fields}).
        \item They are unique given a starting point $p\in U$.
    \end{enumerate}
    \item An incomplete vector field is one such as the "all roads lead to Rome" vector field where everything always points inward. This is because integral curves cannot be defined for all "time" (real numbers, positive and negative).
    \item The proofs are in the book; they require an existence/uniqueness result for ODEs and the implicit function theorem.
    \item Aside: $f:U\to\R$, $v$ a vector field, implies that $L_vf=0$ means that $f$ is constant along all the integral curves of $v$. This also means that $f$ is integral for $v$.
    \item \textbf{Pullback} (of 1-forms): If $F:U\to V$, $d:\ome[0]{U}\to\ome[1]{U}$, and $d:\ome[0]{V}\to\ome[1]{V}$, then we get an induced map $F^*:\ome[0]{V}\to\ome[0]{U}$. If $f:V\to\R$, then $f\circ F$ is involved.
    \begin{itemize}
        \item We're basically saying that if we have $\Hom(A,X)$ (the set of all functions from $A$ to $X$) and $\Hom(B,X)$, then if we have $F:A\to B$, we get an induced map $F^*:\Hom(B,X)\to\Hom(A,X)$ that is precomposed with $F$.
    \end{itemize}
    \item \marginnote{4/27:}Announcements.
    \begin{itemize}
        \item No class this Friday, next Monday.
        \item Midterm next Friday.
        \begin{itemize}
            \item Up through Chapter 2.
            \item The exam will likely be computationally heavy.
            \item Compute $\dd$, pullbacks, interior products, Lie derivatives, etc.
            \item Emphasis on Chapter 2 as opposed to Chapter 1 even though it all builds on itself.
            \item He'll probably cook up a few problems too.
        \end{itemize}
        \item There is a recorded lecture for us.
        \begin{itemize}
            \item On Chapter 3 content.
            \item We'll cover Chapter 3 in kind of an impressionistic way as it is.
        \end{itemize}
        \item There are also some notes on the physics stuff.
    \end{itemize}
    \item Vector calculus operations.
    \begin{itemize}
        \item In one dimension, you have functions, and you take derivatives.
        \begin{itemize}
            \item The derivative operation does essentially map $\Omega^0\to\Omega^1$ or $C^\infty(\R)\to C^\infty(\R)$.
        \end{itemize}
        \item In two dimensions, ...
        \begin{itemize}
            \item $\dd^2=0$ reflects the fact that gradient vector fields are curl-free.
        \end{itemize}
        \item If you want to understand the 2D-curl business\dots
        \begin{itemize}
            \item $\crl(v):\R^2\to\R$ is intuitively about balls spinning around in a vector field.
            \item There's also a nice formula to compute it.
            \item And then there's a connection with $\dd:\Omega^1\to\Omega^2$.
        \end{itemize}
        \item In 3D, you can take top-dimensional forms (which are just functions) and bottom-dimensional forms (which are by definition functions) and you can work out an identification between them.
        \item Note that $\crl:\mathfrak{X}(\R^2)\to C^\infty(\R^2)$, where $\mathfrak{X}(\R^2)$ is the space of vector fields.
    \end{itemize}
    \item The musical operator $\sharp$ identifies forms with vector fields, i.e., $\sharp:\Omega^1\to\mathfrak{X}(\R^2)$.
    \item Properties of exterior derivatives $\dd:\ome[k]{U}\to\ome[k+1]{U}$.
    \begin{enumerate}
        \item $\dd{(\omega_1+\omega_2)}=\dd{\omega_1}+\dd{\omega_2}$ and $\dd{(\lambda\omega)}=\lambda\dd{\omega}$.
        \item Product rule $\dd{(\omega_1\wedge\omega_2)}=\dd{\omega_1}\wedge\omega_2+(-1)^k\omega_1\wedge\dd{\omega_2}$.
        \begin{itemize}
            \item Special case $k=\ell=0$. Then
            \begin{equation*}
                \dd{(fg)} = g\dd{f}+f\dd{g}
            \end{equation*}
            which is the usual product rule for gradient.
            \item Claim:
            \begin{equation*}
                \dd{\left( \sum_If_I\dd{x_I} \right)} = \sum_I\dd{f_I}\wedge\dd{x_I}
            \end{equation*}
            \begin{itemize}
                \item Let $\omega_1\in\Omega^k$ and $\omega_2\in\Omega^\ell$ be defined by
                \begin{align*}
                    \omega_1 &= \sum_If_I\dd{x_I}&
                    \omega_2 &= \sum_Jg_J\dd{x_J}
                \end{align*}
                where we're summing over all $I$ such that $|I|=k$ and all $J$ such that $|J|=\ell$. Then
                \begin{align*}
                    \omega_1\wedge\omega_2 &= \sum_{I,J}f_Ig_J\dd{x_I}\wedge\dd{x_J}
                    \dd{(\omega_1\wedge\omega_2)} &= \sum_{I,J}\dd{(f_Ig_J)}\wedge\dd{x_I}\wedge\dd{x_J}
                \end{align*}
                \item Note that
                \begin{equation*}
                    \dd{(f_Ig_J)} = g_J\dd{f_I}+f_I\dd{g_J}
                \end{equation*}
                and
                \begin{equation*}
                    \dd{g_J}\wedge\dd{x_I} = (-1)^k\dd{x_I}\wedge\dd{g_J}
                \end{equation*}
                \item These identities allow us to take the previous equation to
                \begin{align*}
                    \dd{(\omega_1\wedge\omega_2)} &= \sum_{I,J}g_J\dd{f_I}\wedge\dd{x_I}\wedge\dd{x_J}+(-1)^kf_I\dd{x_I}\wedge\dd{g_J}\wedge\dd{x_J}\\
                    &= \sum_{I,J}(\dd{f_I}\wedge\dd{x_I})\wedge(g_J\dd{x_J})+\sum_{I,J}(f_I\dd{x_I})\wedge(dd{g_J}\wedge\dd{x_J})\\
                    &= \dd{\omega_1}\wedge\omega_2+(-1)^k\omega_1\dd{\omega_2}
                \end{align*}
            \end{itemize}
        \end{itemize}
        \item $\dd^2=0$.
        \begin{itemize}
            \item Let $\omega=\sum_If_I\dd{x_I}$.
            \item Then
            \begin{align*}
                \dd^2(\omega) &= \dd(\dd{\omega})\\
                &= \dd(\sum_I\dd{f_I}\wedge\dd{x_I})\\
                &= \sum_I\dd(\dd{f_I}\wedge\dd{x_I})\tag*{Property 1}\\
                &= \sum_I\dd(\dd{f_I})\wedge\dd{x_I}\tag*{Property 2}
            \end{align*}
            so it suffices to just show that $\dd^2f=0$ for all $f\in\Omega^0$.
            \item We know that $\dd{f}=\sum_{i=1}^n\pdv*{f}{x_i}\dd{x_i}$. Thus,
            \begin{align*}
                \dd(\dd{f}) &= \sum_i\dd(\pdv{f}{x_i})\wedge\dd{x_i}\\
                &= \sum_{i,j}\pdv{f}{x_j}{x_i}\dd{x_j}\wedge\dd{x_i}\\
                &= 0
            \end{align*}
            \item The last equality holds because of commuting partial derivatives for smooth $f$, and the fact that changing order introduces a negative sign by some property.
        \end{itemize}
    \end{enumerate}
    \item In fact, if we fix $\dd^0:\ome[0]{U}\to\ome[1]{U}$ to be the "gradient," then these properties characterize the function $\dd$ on its domain and codomain. In particular, $\dd$ is the unique function on its domain and codomain that satisfies these properties.
    \begin{itemize}
        \item We define it by
        \begin{equation*}
            \dd{\left( \sum_If_I\dd{x_I} \right)} = \sum_I\dd{f_I}\wedge\dd{x_I}
        \end{equation*}
        \item The above properties characterize it axiomatically.
        \item We can prove this uniqueness theorem.
    \end{itemize}
    \item \textbf{Closed} (form): A form $\omega\in\ome[k]{U}$ such that $\dd{\omega}=0$.
    \item \textbf{Exact} (form): A form $\omega\in\ome[k]{U}$ such that $\omega=\dd{\eta}$ for some $\eta\in\ome[k-1]{U}$.
    \item $\dd^2=0$ implies closed and exact implies closed.
    \item \textbf{Poincar\'{e} lemma}: Locally closed forms are exact.
    \item \marginnote{5/4:}Klug got his flight to his wedding paid for by giving a talk at a nearby institution!
    \item Homework 3 now due Monday (the stuff will be on the exam though).
    \item Office hours today from 5:00-6:00.
    \item Exam Friday.
    \item Next week will be Chapter 3.
    \begin{itemize}
        \item Integration of top-dimensional forms, i.e., if we're in 2D space, we'll integrate 2D forms; in 3D space, we'll integrate 3D forms, etc.
    \end{itemize}
    \item Pullbacks of $k$-forms.
    \begin{itemize}
        \item Let $F:U\to V$ be smooth where $U\subset\R^n$ and $V\subset\R^m$.
        \item This induces $F^*:\ome[k]{V}\to\ome[k]{U}$.
        \item We have $\dd{F_p}:T_p\R^n\to T_{F(p)}\R^m$, which also induces $\dd{F_p^*}:\lam[k]{T_{F(p)}^*\R^m}\to\lam[k]{T_p^*\R^n}$.
        \item Note that $F^*$ maps $\omega\mapsto F^*\omega$ where $F^*\omega_p=\dd{F_p^*\omega_{F(p)}}$.
    \end{itemize}
    \item In formulas\dots
    \begin{align*}
        \omega &= \sum_I\varphi_I\dd{x_I}&
        F^*\omega &= \sum_IF^*\varphi_I\dd{F_I}
    \end{align*}
    \begin{itemize}
        \item $\varphi_I$ is just a function.
        \item Recall that $F^*\varphi_I=\varphi_I\circ F:U\to\R$.
        \item If $I=(i_1,\dots,i_k)$, then $\dd{F_I}=\dd{F_{i_1}}\wedge\cdots\wedge\dd{F_{i_k}}$.
        \item Recall that $F_{i_j}:U\to\R$ sends $x\mapsto x_{i_j}$ (the component of $F$).
        \item There is a derivation that gets you from the above abstract definition of the pullback to the below concrete form.
    \end{itemize}
    \item Note that $\dd{F_p}$ is the kind of thing we worked on last quarter?
    \item Properties of the pullback (let $U\xrightarrow{F}V\xrightarrow{G}W$).
    \begin{enumerate}
        \item $F^*$ is linear.
        \item $F^*(\omega_1\wedge\omega_2)=F^*\omega_1\wedge F^*\omega_2$.
        \item $(F\circ G)^*=G^*\circ F^*$.
        \item $\dd\circ F^*=F^*\circ\dd$.
        \emph{picture; Commutative diagram}
    \end{enumerate}
    \item Properties 1-3 follow from our Chapter 1 pointwise properties.
    \begin{itemize}
        \item They also yield the explicit formula for $F^*\omega$ given above.
    \end{itemize}
    \item Property 4:
    \begin{itemize}
        \item First: Recall that the following diagram holds.
        \emph{picture}
        \item Check: $\dd{F_I}=F^*\dd{x_I}$ where $\dd{F_{i_1}}\wedge\cdots\wedge\dd{F_{i_k}}$ where $I=(i_1,\dots,i_k)$.
        \item Now we prove the property by taking
        \begin{align*}
            \dd{F_I} &= F^*(\dd{x_{i_1}}\wedge\cdots\wedge\dd{x_{i_k}})\\
            &= F^*\dd{x_{i_1}}\wedge\cdots\wedge F^*\dd{x_{i_k}}\tag*{Property 2}\\
            &= \dd(F^*x_{i_1})\wedge\cdots\wedge\dd{(F^*x_{i_k})}\\
            &= \dd{F_{i_1}}\wedge\cdots\wedge\dd{F_{i_k}}
        \end{align*}
        \item Now we have that if $\omega=\sum_I\varphi_I\dd{x_I}$, then
        \begin{align*}
            \dd(F^*\omega) &= \dd(\sum_IF^*\varphi_I\dd{F_I})\\
            &= \sum_I\dd(F^*\varphi_I\wedge\dd{F_I})\\
            &= \sum_I\dd(F^*\varphi_I)\wedge\dd{F_I}\\
            &= \sum_IF^*\dd{\varphi_I}\wedge F^*\dd{x_I}\\
            &= \sum_IF^*(\dd{\varphi_I}\wedge\dd{x_I})\\
            &= F^*\left( \sum_I\dd{\varphi_I}\wedge\dd{x_I} \right)\\
            &= F^*\dd{\omega}
        \end{align*}
        where the second equality holds by the linearity of $\dd$ and we insert the wedge because multiplication is the same as wedging a zero-form, the third equality holds by the product rule $\dd^2=0$, the fourth equality holds because $\dd$ and $F^*$ commute for 0-forms, and the fifth equality holds by Property 2.
    \end{itemize}
    \item $\dd^2=0$ generalizes curl and all of those identities.
    \item Two other operations.
    \item \textbf{Interior product}: Given $v$ a vector field on $U$, we have $\iota_v:\ome[k]{U}\to\ome[k-1]{U}$ that sends $\omega\mapsto\iota_v\omega$.
    \begin{itemize}
        \item Its properties follow from the properties of the pointwise stuff.
        \begin{enumerate}
            \item $\iota_v(\omega_1+\omega_2)=\iota_v\omega_1+\iota_v\omega_2$.
            \item $\iota_v(\omega_1\wedge\omega_2)=\cdots$.
            \item $\iota_v\circ\iota_w=-\iota_w\circ\iota_v$.
        \end{enumerate}
    \end{itemize}
    \item \textbf{Lie derivative}: If $v$ is a vector field on $U$, then $L_v:\ome[k]{U}\to\ome[k]{U}$ sends $\omega\mapsto\dd{\iota_v\omega}+\iota_v\dd{\omega}$.
    \begin{itemize}
        \item Note that we use $\iota$ to drop the index and $\dd$ to raise it back up, and then vice versa.
    \end{itemize}
    \item Check: Agrees with previous definition for $\Omega^0$.
    \item Cartan's magic formula is what we're taking to be the definition of the Lie derivative.
    \item Properties.
    \begin{enumerate}
        \item $L_v\circ\dd=\dd\circ L_v$.
        \item $L_v(\omega\wedge\eta)=L_v\omega\wedge\eta+\omega\wedge L_v\eta$.
        \begin{itemize}
            \item Proof:
            \begin{align*}
                \dd(\iota_v\dd+\dd\iota_v) &= \dd\iota_v\dd\\
                &= \iota_v(\iota_v\dd+\dd\iota_v)
            \end{align*}
        \end{itemize}
    \end{enumerate}
    \item We should find an explicit formula for the Lie derivative.
    \begin{itemize}
        \item Your vector field will be of the form
        \begin{equation*}
            v = \sum f_i\pdv*{x_i}
        \end{equation*}
        \item Your form will be of the form
        \begin{equation*}
            \omega = \sum\varphi_I\dd{x_I}
        \end{equation*}
    \end{itemize}
\end{itemize}




\end{document}